{"cells":[{"cell_type":"markdown","metadata":{"id":"pU-wr0vmkQVU"},"source":["# 고혈압 분석 모델\n","## @author: sh22h\n","\n","- year0_NA를 DataFrame으로 불러오고 4개로 나눔\n","  - binary: 범주형(binary) 변수, 0 / 1 로 변경\n","  - categoryH0: 계층 없는 범주형(>3) 변수, one-hot-encoding\n","  - categoryH1: 계층 있는 범주형 변수, 표준화\n","  - ctn:연속형 변수, 정규화, 표준화 \n","  - hyperTension: 고혈압\n","\n","- 각각 정규화 또는 표준화한 후 변수는 X 고혈압은 y로 둠\n","  - 정규화(normalization): 0, 1\n","  - 표준화(standardization): 평균: 0 표준편차: 1\n","  - 계층화(quantile transform): 4분위 수\n","\n","## 학습 모델\n","\n","- 0차\n","  - 로컬에서 구현\n","\n","- 1차\n","  - 2021-07-20\n","  - normalize_ctn\n","  - \n","  ```\n","  model = Sequential()\n","  model.add(Dense(12, input_dim=52, activation='relu'))  # input layer requires input_dim param\n","  model.add(Dense(15, activation='relu'))\n","  model.add(Dense(8, activation='relu'))\n","  model.add(Dense(10, activation='relu'))\n","  model.add(Dense(1, activation='sigmoid'))  # sigmoid instead of relu for final probability between 0 and 1\n","  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n","  history = model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=0)\n","  scores = model.evaluate(X_test, y_test)\n","  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n","  ```\n","\n","- 2차\n","  - 2021-07-26\n","  - Decision Tree 구현\n","\n","- 3차\n","  - 2021-08-02\n","  - one-hot encoding 구현\n","\n","- 4차\n","  - 2021-08-07\n","  - 전처리 개선\n","  - Keras Tunor 사용 준비\n","  - P1 ~ P4 모델 구현\n","\n","- 5차\n","  - 2021-08-08\n","  - 데이터 결측값 관리\n","    - TOTALC 유의미한 값: 15개\n","    - 키, 몸무게 결측값 매우 많음\n","  - 데이터 결측값 제거\n","    - TOTALC 삭제\n","    - KNNImputer로 결측값 채우기\n","    - https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html#sklearn.impute.KNNImputer\n","\n","- 6차\n","  - 2021-08-12\n","  - 데이터 결측값 관리\n","    - 변수 모두 포함하라!\n","    - 범주형: 최빈값\n","    - 수치형: 평균값(kNN)\n","    - TOTALC 포함하라\n","    - 주말까지\n","  - DicisionTree 보는 법을 해석하라.\n","  - 모델 정확도 올리기\n","\n","- 7차\n","  - 2021-08-23\n","  - unit 통일\n","  - dropout 통일\n","  - 모델 정확도 여전히 안좋음\n","\n","- 8차\n","  - 2021-08-24\n","  - unit, dropout 다시 분리\n","  - 레이어 늘림\n","\n","- 9차\n","  - 2021-08-26\n","  - 변수 중요도 낮은 변수 일부 제거하고 모델 돌려보기\n","    - 영향을 조금이라도 주는 것\n","      1. 'AS1_AGE'\n","      2. 'AS1_WEIGHT'\n","      3. 'AS1_B18'\n","      4. 'AS1_SEX'\n","      5. 'P3'\n","      6. 'AS1_B01'\n","      7. 'AS1_B04'\n","    - 나머지, 영향 없음.\n","\n","- 10차\n","  - 2021-08-29\n","  - unit 통일\n","  - dropout 통일\n"," \n","- 11차\n","  - 2021-08-30\n","  - max_epoch = 10으로 통일\n","\n","- 12차\n","  - 데이터셋 변경\n","\n","- 13차\n","  - 2021-09-09\n","  - 데이터셋 변경\n","    - P1 ~ P4 -> FA1 ~ FA5 \n","    - columns 54\n","\n","- 14차\n","  - 2021-09-13\n","  - 데이터 추가\n","    - AS1_WAIST3_A\n","    - 허리둘레\n","    - 계층있는 연속형\n","    - columns: 55\n","\n","- 15차\n","  - 2021-09-26\n","  - 누락 되었던 식품군 F1 ~ F17 데이터 추가\n","  - 모델 제작에는 사용하지 않음\n","\n","- 16차\n","  - 2021-10-01\n","  - JOBB 추가\n","  - 키 대신에 BMI 넣음\n","  - FA를 DP로 변경\n","\n","- 17차\n","  - 2022-05-04\n","  - _1000 변수만으로 모델 학습\n","\n","- 18차\n","  - 2022-05-13\n","  - 혈압을 예측하는 회귀모델 구현\n","  - _1000 변수 + 원래 쓰던거\n","  - 77777 to 0\n","    - AS1_DRDUA: 77777 to 0\n","    - AS1_HVSMAM: 77777 to 0\n","\n","  - 그냥 삭제\n","    - \n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22890,"status":"ok","timestamp":1652969961749,"user":{"displayName":"황승현","userId":"10828741460016505216"},"user_tz":-540},"id":"RjiU0YHvfgjx","outputId":"99539963-a041-4486-8a06-229b11a13ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv1D, GlobalMaxPooling1D, Embedding\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"QCqf1xFSTdCV"},"source":["## 데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"h1bbzKdQXAgj"},"source":["### 데이터 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpUuJ2w6-ww5"},"outputs":[],"source":["# 종속변수에 결측값이 있는 열은 제외하고 불러옴. 데이터의 순수성 지킴\n","dataset = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/HyperTension_Returns/dataset220513_3.xlsx',\n","                        index_col=0, na_values=['NA', ' ', '#NULL!','#DIV/0!']).dropna(subset=['AS1_DRUGHTCU', 'AS1_BPLIE2S_A', 'AS1_BPLIE2D_A'])\n","dataset"]},{"cell_type":"code","source":["dataset.info()"],"metadata":{"id":"D31PHRTFVUGO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 데이터 그룹 별로 분류\n","\n","'AS1_HEIGHT', 'AS1_WEIGHT'는 결측값이 매우 높은데 어떻게 스케일링 해야할까?\n","\n","- 40 50 60대 남녀 6개 그룹으로 나눔\n","- 각 그룹의 평균값으로 대치\n","- np.select 사용"],"metadata":{"id":"70E1DXlxSFZL"}},{"cell_type":"code","source":["condition = [(dataset['AS1_SEX'] == 1 ) & (dataset['AS1_AGE'] >= 60),  # 60대 남자\n","             (dataset['AS1_SEX'] == 1 ) & (dataset['AS1_AGE'] >= 50),  # 50대 남자\n","             (dataset['AS1_SEX'] == 1 ) & (dataset['AS1_AGE'] >= 40),  # 40대 남자\n","             (dataset['AS1_SEX'] == 2 ) & (dataset['AS1_AGE'] >= 60),  # 60대 여자\n","             (dataset['AS1_SEX'] == 2 ) & (dataset['AS1_AGE'] >= 50),  # 50대 여자\n","             (dataset['AS1_SEX'] == 2 ) & (dataset['AS1_AGE'] >= 40)   # 40대 여자\n","            ]\n","choice = ['M60', 'M50', 'M40', 'F60', 'F50', 'F40']\n","\n","dataset['group'] = np.select(condition, choice, default=np.nan)"],"metadata":{"id":"cM8HjqyrSIkd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaxzk4_8TNNp"},"source":["### dataset 결측값 대치"]},{"cell_type":"markdown","source":["#### 결측값이 너무 많은 데이터는 제거\n","- AS1_TOTALC\n","- AS1_FMHTREL1A\n","- AS1_FMDMREL1A\n","- AS1_FMHEREL1A\n","- AS1_FMCVAREL1A\n","- AS1_FMCDREL1A\n","- AS1_FMCDREL1AG\n","- AS1_FMCHREL1A\n","- AS1_FMPVREL1A\n","- AS1_FMLPREL1A\n"],"metadata":{"id":"gk2PCVCeWHFh"}},{"cell_type":"code","source":["dataset = dataset.drop(columns=['AS1_TOTALC', 'AS1_FMHTREL1A', 'AS1_FMDMREL1A',\n","                                'AS1_FMHEREL1A', 'AS1_FMCVAREL1A', 'AS1_FMCDREL1AG',\n","                                'AS1_FMCDREL1A', 'AS1_FMCHREL1A', \n","                                'AS1_FMPVREL1A', 'AS1_FMLPREL1A'])"],"metadata":{"id":"hT89zbkAWGxG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### AS1_WAIST3_A "],"metadata":{"id":"DJ0cTCdpW9Lx"}},{"cell_type":"code","source":["dataset = dataset.dropna(subset=['AS1_WAIST3_A'])"],"metadata":{"id":"c0V7_1AKW3R3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### AS1_HEIGHT, AS1_WEIGHT"],"metadata":{"id":"HkADi7wKSYJ5"}},{"cell_type":"code","source":["fill_mean_func = lambda g: g.fillna(g.mean()) # 각 그룹별 평균으로 결측값 대치\n","\n","dataset['AS1_HEIGHT'] = dataset.groupby('group')['AS1_HEIGHT'].apply(fill_mean_func)\n","dataset['AS1_WEIGHT'] = dataset.groupby('group')['AS1_WEIGHT'].apply(fill_mean_func)"],"metadata":{"id":"GDjEGwwFSNH3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### AS1_BMI"],"metadata":{"id":"P5zFKVBcSgFE"}},{"cell_type":"code","source":["dataset['AS1_BMI'] = np.where(pd.notnull(dataset['AS1_BMI']) == True, dataset['AS1_BMI'], dataset['AS1_WEIGHT'] / ((dataset['AS1_HEIGHT']/100) ** 2))"],"metadata":{"id":"Wvr8T8GHSXMJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 마지막까지 남아있는 것 dropna, 완료\n","\n"],"metadata":{"id":"k1peNkWcoFhX"}},{"cell_type":"code","source":["dataset.dropna(inplace=True)"],"metadata":{"id":"Z30FKpzdoFFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kb0rQKyQhQ_T","executionInfo":{"status":"ok","timestamp":1652448891779,"user_tz":-540,"elapsed":221,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"7e01d74c-cbf2-4274-b762-b46fad2a3d71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 8997 entries, EPI20_026_2_000002 to EPI20_026_2_010030\n","Data columns (total 56 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   AS1_SEX        8997 non-null   int64  \n"," 1   AS1_AGE        8997 non-null   int64  \n"," 2   AS1_HEIGHT     8997 non-null   float64\n"," 3   AS1_WEIGHT     8997 non-null   float64\n"," 4   AS1_BMI        8997 non-null   float64\n"," 5   AS1_WAIST3_A   8997 non-null   float64\n"," 6   AS1_EDUA       8997 non-null   int64  \n"," 7   AS1_INCOME     8997 non-null   int64  \n"," 8   AS1_DRINK      8997 non-null   int64  \n"," 9   AS1_DRDUA      8997 non-null   int64  \n"," 10  AS1_SMOKEA     8997 non-null   int64  \n"," 11  AS1_HVSMAM     8997 non-null   float64\n"," 12  AS1_HVSMDU     8997 non-null   int64  \n"," 13  AS1_PHYSTB     8997 non-null   int64  \n"," 14  AS1_PHYSIT     8997 non-null   int64  \n"," 15  AS1_PHYACTL    8997 non-null   int64  \n"," 16  AS1_PHYACTM    8997 non-null   int64  \n"," 17  AS1_PHYACTH    8997 non-null   int64  \n"," 18  AS1_HEALTH     8997 non-null   int64  \n"," 19  AS1_TIED       8997 non-null   int64  \n"," 20  AS1_SLPAMTM    8997 non-null   int64  \n"," 21  AS1_SLPAMSF    8997 non-null   int64  \n"," 22  AS1_STRPHYSJ   8997 non-null   int64  \n"," 23  AS1_RGMEALFQA  8997 non-null   int64  \n"," 24  AS1_B01        8997 non-null   int64  \n"," 25  AS1_B02_1000   8997 non-null   float64\n"," 26  AS1_B03_1000   8997 non-null   float64\n"," 27  AS1_B04_1000   8997 non-null   float64\n"," 28  AS1_B05_1000   8997 non-null   float64\n"," 29  AS1_B06_1000   8997 non-null   float64\n"," 30  AS1_B07_1000   8997 non-null   float64\n"," 31  AS1_B08_1000   8997 non-null   float64\n"," 32  AS1_B09_1000   8997 non-null   float64\n"," 33  AS1_B10_1000   8997 non-null   float64\n"," 34  AS1_B11_1000   8997 non-null   float64\n"," 35  AS1_B12_1000   8997 non-null   float64\n"," 36  AS1_B13_1000   8997 non-null   float64\n"," 37  AS1_B14_1000   8997 non-null   float64\n"," 38  AS1_B15_1000   8997 non-null   float64\n"," 39  AS1_B16_1000   8997 non-null   float64\n"," 40  AS1_B17_1000   8997 non-null   float64\n"," 41  AS1_B18_1000   8997 non-null   float64\n"," 42  AS1_B19_1000   8997 non-null   float64\n"," 43  AS1_B20_1000   8997 non-null   float64\n"," 44  AS1_B21_1000   8997 non-null   float64\n"," 45  AS1_B23_1000   8997 non-null   float64\n"," 46  AS1_B24_1000   8997 non-null   float64\n"," 47  FA1            8997 non-null   int64  \n"," 48  FA2            8997 non-null   int64  \n"," 49  FA3            8997 non-null   int64  \n"," 50  FA4            8997 non-null   int64  \n"," 51  FA5            8997 non-null   int64  \n"," 52  AS1_DRUGHTCU   8997 non-null   int64  \n"," 53  AS1_BPLIE2S_A  8997 non-null   float64\n"," 54  AS1_BPLIE2D_A  8997 non-null   float64\n"," 55  group          8997 non-null   object \n","dtypes: float64(29), int64(26), object(1)\n","memory usage: 3.9+ MB\n"]}]},{"cell_type":"code","source":["sum(dataset.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBo0D5qgYWsf","executionInfo":{"status":"ok","timestamp":1652448895675,"user_tz":-540,"elapsed":218,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"81c34d10-dc2a-4823-a2a0-a205d6188cde"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"MwHdLXJThIsG","executionInfo":{"status":"ok","timestamp":1652448896710,"user_tz":-540,"elapsed":3,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"5cd12ed5-39e8-4108-a7da-ddd64d4e0b99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    AS1_SEX  AS1_AGE  AS1_HEIGHT  AS1_WEIGHT       AS1_BMI  \\\n","RID                                                                          \n","EPI20_026_2_000002        1       66  164.677632   62.936330     23.207705   \n","EPI20_026_2_000004        2       56  153.679198   68.000000  99999.000000   \n","EPI20_026_2_000006        2       43  155.673302   70.000000     28.884827   \n","EPI20_026_2_000007        1       56  176.000000   71.000000     22.920971   \n","EPI20_026_2_000010        1       50  175.000000   83.000000     27.102041   \n","...                     ...      ...         ...         ...           ...   \n","EPI20_026_2_010025        1       55  166.869880   67.493373     24.238471   \n","EPI20_026_2_010026        2       41  165.000000   60.000000     22.038567   \n","EPI20_026_2_010028        1       40  168.589552   73.000000     25.683934   \n","EPI20_026_2_010029        1       53  166.869880   65.000000     25.000000   \n","EPI20_026_2_010030        1       55  171.000000   67.493373     23.081759   \n","\n","                    AS1_WAIST3_A  AS1_EDUA  AS1_INCOME  AS1_DRINK  AS1_DRDUA  \\\n","RID                                                                            \n","EPI20_026_2_000002     68.000000         1           1          3          5   \n","EPI20_026_2_000004     89.333333         1           4          1          1   \n","EPI20_026_2_000006     81.000000         2           4          3          1   \n","EPI20_026_2_000007     84.000000         6           8          3          5   \n","EPI20_026_2_000010     94.000000         3           3          3          5   \n","...                          ...       ...         ...        ...        ...   \n","EPI20_026_2_010025     88.000000         3           2          3          5   \n","EPI20_026_2_010026     73.333333         3           6          1          1   \n","EPI20_026_2_010028     84.000000         3           5          3          5   \n","EPI20_026_2_010029     87.000000         1           2          3          5   \n","EPI20_026_2_010030      0.000000         3           3          3          5   \n","\n","                    ...  AS1_B24_1000  FA1  FA2  FA3  FA4   FA5  AS1_DRUGHTCU  \\\n","RID                 ...                                                         \n","EPI20_026_2_000002  ...     61.317678   24   56   42    0   786             1   \n","EPI20_026_2_000004  ...    126.462816   75  695   89    0   735             1   \n","EPI20_026_2_000006  ...    133.461354    3   90  594  115   638             1   \n","EPI20_026_2_000007  ...     59.332509   12   62   20   30   818             1   \n","EPI20_026_2_000010  ...    113.557358   75   43   39   30   960             1   \n","...                 ...           ...  ...  ...  ...  ...   ...           ...   \n","EPI20_026_2_010025  ...     84.629187   67  196  277   25  1709             1   \n","EPI20_026_2_010026  ...    106.329114   16   28  292   20   729             1   \n","EPI20_026_2_010028  ...     85.513078   30    1  115   20   746             1   \n","EPI20_026_2_010029  ...     55.441478   37    2   15    0   960             1   \n","EPI20_026_2_010030  ...     58.245614    8    0   79    0   735             1   \n","\n","                    AS1_BPLIE2S_A  AS1_BPLIE2D_A  group  \n","RID                                                      \n","EPI20_026_2_000002          128.0           80.0    M60  \n","EPI20_026_2_000004          158.0           81.0    F50  \n","EPI20_026_2_000006          146.0           81.0    F40  \n","EPI20_026_2_000007          108.0           75.0    M50  \n","EPI20_026_2_000010          122.0           86.0    M50  \n","...                           ...            ...    ...  \n","EPI20_026_2_010025          120.0           70.0    M50  \n","EPI20_026_2_010026           73.0           47.0    F40  \n","EPI20_026_2_010028          121.0           85.0    M40  \n","EPI20_026_2_010029          109.0           70.0    M50  \n","EPI20_026_2_010030          125.0           90.0    M50  \n","\n","[8997 rows x 56 columns]"],"text/html":["\n","  <div id=\"df-a6b07216-2a9e-44a3-9263-08ecd006eb4b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AS1_SEX</th>\n","      <th>AS1_AGE</th>\n","      <th>AS1_HEIGHT</th>\n","      <th>AS1_WEIGHT</th>\n","      <th>AS1_BMI</th>\n","      <th>AS1_WAIST3_A</th>\n","      <th>AS1_EDUA</th>\n","      <th>AS1_INCOME</th>\n","      <th>AS1_DRINK</th>\n","      <th>AS1_DRDUA</th>\n","      <th>...</th>\n","      <th>AS1_B24_1000</th>\n","      <th>FA1</th>\n","      <th>FA2</th>\n","      <th>FA3</th>\n","      <th>FA4</th>\n","      <th>FA5</th>\n","      <th>AS1_DRUGHTCU</th>\n","      <th>AS1_BPLIE2S_A</th>\n","      <th>AS1_BPLIE2D_A</th>\n","      <th>group</th>\n","    </tr>\n","    <tr>\n","      <th>RID</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>EPI20_026_2_000002</th>\n","      <td>1</td>\n","      <td>66</td>\n","      <td>164.677632</td>\n","      <td>62.936330</td>\n","      <td>23.207705</td>\n","      <td>68.000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>61.317678</td>\n","      <td>24</td>\n","      <td>56</td>\n","      <td>42</td>\n","      <td>0</td>\n","      <td>786</td>\n","      <td>1</td>\n","      <td>128.0</td>\n","      <td>80.0</td>\n","      <td>M60</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_000004</th>\n","      <td>2</td>\n","      <td>56</td>\n","      <td>153.679198</td>\n","      <td>68.000000</td>\n","      <td>99999.000000</td>\n","      <td>89.333333</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>126.462816</td>\n","      <td>75</td>\n","      <td>695</td>\n","      <td>89</td>\n","      <td>0</td>\n","      <td>735</td>\n","      <td>1</td>\n","      <td>158.0</td>\n","      <td>81.0</td>\n","      <td>F50</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_000006</th>\n","      <td>2</td>\n","      <td>43</td>\n","      <td>155.673302</td>\n","      <td>70.000000</td>\n","      <td>28.884827</td>\n","      <td>81.000000</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>133.461354</td>\n","      <td>3</td>\n","      <td>90</td>\n","      <td>594</td>\n","      <td>115</td>\n","      <td>638</td>\n","      <td>1</td>\n","      <td>146.0</td>\n","      <td>81.0</td>\n","      <td>F40</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_000007</th>\n","      <td>1</td>\n","      <td>56</td>\n","      <td>176.000000</td>\n","      <td>71.000000</td>\n","      <td>22.920971</td>\n","      <td>84.000000</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>59.332509</td>\n","      <td>12</td>\n","      <td>62</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>818</td>\n","      <td>1</td>\n","      <td>108.0</td>\n","      <td>75.0</td>\n","      <td>M50</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_000010</th>\n","      <td>1</td>\n","      <td>50</td>\n","      <td>175.000000</td>\n","      <td>83.000000</td>\n","      <td>27.102041</td>\n","      <td>94.000000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>113.557358</td>\n","      <td>75</td>\n","      <td>43</td>\n","      <td>39</td>\n","      <td>30</td>\n","      <td>960</td>\n","      <td>1</td>\n","      <td>122.0</td>\n","      <td>86.0</td>\n","      <td>M50</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_010025</th>\n","      <td>1</td>\n","      <td>55</td>\n","      <td>166.869880</td>\n","      <td>67.493373</td>\n","      <td>24.238471</td>\n","      <td>88.000000</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>84.629187</td>\n","      <td>67</td>\n","      <td>196</td>\n","      <td>277</td>\n","      <td>25</td>\n","      <td>1709</td>\n","      <td>1</td>\n","      <td>120.0</td>\n","      <td>70.0</td>\n","      <td>M50</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_010026</th>\n","      <td>2</td>\n","      <td>41</td>\n","      <td>165.000000</td>\n","      <td>60.000000</td>\n","      <td>22.038567</td>\n","      <td>73.333333</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>106.329114</td>\n","      <td>16</td>\n","      <td>28</td>\n","      <td>292</td>\n","      <td>20</td>\n","      <td>729</td>\n","      <td>1</td>\n","      <td>73.0</td>\n","      <td>47.0</td>\n","      <td>F40</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_010028</th>\n","      <td>1</td>\n","      <td>40</td>\n","      <td>168.589552</td>\n","      <td>73.000000</td>\n","      <td>25.683934</td>\n","      <td>84.000000</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>85.513078</td>\n","      <td>30</td>\n","      <td>1</td>\n","      <td>115</td>\n","      <td>20</td>\n","      <td>746</td>\n","      <td>1</td>\n","      <td>121.0</td>\n","      <td>85.0</td>\n","      <td>M40</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_010029</th>\n","      <td>1</td>\n","      <td>53</td>\n","      <td>166.869880</td>\n","      <td>65.000000</td>\n","      <td>25.000000</td>\n","      <td>87.000000</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>55.441478</td>\n","      <td>37</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>0</td>\n","      <td>960</td>\n","      <td>1</td>\n","      <td>109.0</td>\n","      <td>70.0</td>\n","      <td>M50</td>\n","    </tr>\n","    <tr>\n","      <th>EPI20_026_2_010030</th>\n","      <td>1</td>\n","      <td>55</td>\n","      <td>171.000000</td>\n","      <td>67.493373</td>\n","      <td>23.081759</td>\n","      <td>0.000000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>58.245614</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>79</td>\n","      <td>0</td>\n","      <td>735</td>\n","      <td>1</td>\n","      <td>125.0</td>\n","      <td>90.0</td>\n","      <td>M50</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8997 rows × 56 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6b07216-2a9e-44a3-9263-08ecd006eb4b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a6b07216-2a9e-44a3-9263-08ecd006eb4b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a6b07216-2a9e-44a3-9263-08ecd006eb4b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["dataset.to_pickle('/content/drive/MyDrive/Colab Notebooks/HyperTension_Returns/ReplacedDatasets.pkl')\n","dataset.to_csv('/content/drive/MyDrive/Colab Notebooks/HyperTension_Returns/ReplacedDatasets.csv')"],"metadata":{"id":"RO2rH1sWoUDx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset에 있는 변수 분리\n","# 범주형, 연속형 등으로 분리하여 raw_var 형태로 저장하여 각각 관리한다.\n","\n","# 종속변수\n","label = \n","\n","# 범주형(binary, 0 or 1)\n","raw_binary = dataset.reindex(columns=['AS1_SEX', 'AS0_TIED', 'AS0_SLPAMSF', 'AS1_STRPHYSJ'])\n","col_b = raw_binary.columns\n","\n","# 범주형(계층 없음, without hierarchy)\n","# raw_categoryH0 = dataset.reindex(columns=['AS1_INSUR'])\n","# col_H0 = raw_categoryH0.columns\n","\n","# 범주형(계층 있음, with hierarchy)\n","raw_categoryH1 = dataset.reindex(columns=['AS1_EDUA', 'AS1_INCOME', 'AS1_DRINK', 'AS1_DRDUA',\n","                                          'AS1_SMOKEA', 'AS1_PHYSTB', 'AS1_PHYSIT', 'AS1_PHYACTL',\n","                                          'AS1_PHYACTM', 'AS1_PHYACTH', 'AS1_HEALTH'\n","                                          ])\n","col_H1 = raw_categoryH1.columns\n","\n","# 연속형 변수\n","raw_ctn = dataset.reindex(columns=['AS1_AGE', 'AS1_HVSMAM', 'AS1_HVSMDU', 'AS1_TOTALC',\n","                                   'AS1_SLPAMTM', 'AS1_RGMEALFQA',\n","                                   'AS1_HEIGHT', 'AS1_WEIGHT', 'AS1_WAIST3_A',\n","                                   'AS1_B01', 'AS1_B02', 'AS1_B03', 'AS1_B04', 'AS1_B05',\n","                                   'AS1_B06', 'AS1_B07', 'AS1_B08', 'AS1_B09', 'AS1_B10',\n","                                   'AS1_B11', 'AS1_B12', 'AS1_B13', 'AS1_B14', 'AS1_B15',\n","                                   'AS1_B16', 'AS1_B17', 'AS1_B18', 'AS1_B19', 'AS1_B20',\n","                                   'AS1_B21', 'AS1_B23', 'AS1_B24',\n","                                   'DP1', 'DP2', 'DP3', 'DP4', 'DP5',\n","                                   ])\n","col_c = raw_ctn.columns"],"metadata":{"id":"YuUHTR48QBPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-_FjUQQOI9H"},"outputs":[],"source":["# 연속형 변수\n","raw_X = dataset.reindex(columns=['AS1_B02_1000', 'AS1_B03_1000', 'AS1_B04_1000',\n","                                 'AS1_B05_1000', 'AS1_B06_1000', 'AS1_B07_1000',\n","                                 'AS1_B08_1000', 'AS1_B09_1000', 'AS1_B10_1000',\n","                                 'AS1_B11_1000', 'AS1_B12_1000', 'AS1_B13_1000',\n","                                 'AS1_B14_1000', 'AS1_B15_1000', 'AS1_B16_1000',\n","                                 'AS1_B17_1000', 'AS1_B18_1000', 'AS1_B19_1000',\n","                                 'AS1_B20_1000', 'AS1_B21_1000', 'AS1_B23_1000',\n","                                 'AS1_B24_1000'\n","                                 ])\n","idx = raw_X.index\n","col = raw_X.columns\n","\n","y = dataset['HYPERTENSION']"]},{"cell_type":"markdown","metadata":{"id":"5qoRVFu1of6M"},"source":["### dataset 스케일링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUFekSPquYXB"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n","from sklearn.model_selection import train_test_split\n","\n","scaler0 = StandardScaler()\n","scaler1 = MinMaxScaler()\n","scaler2 = QuantileTransformer()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mx2lUtOSW1bJ"},"outputs":[],"source":["X = pd.DataFrame(QuantileTransformer().fit_transform(raw_X), index=idx, columns=col)"]},{"cell_type":"markdown","source":["## 피어슨 상관계수 분석"],"metadata":{"id":"DenTU-_PXPMu"}},{"cell_type":"code","source":["df = pd.concat([X, y], axis=1)"],"metadata":{"id":"pk5bDPVuYnq_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.corr()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":864},"id":"i6RybQFnXWPR","executionInfo":{"status":"ok","timestamp":1652361178195,"user_tz":-540,"elapsed":4,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"5ab7b2aa-fa9a-4d38-d4e7-7c922436ade1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              AS1_B02_1000  AS1_B03_1000  AS1_B04_1000  AS1_B05_1000  \\\n","AS1_B02_1000      1.000000      0.730212     -0.847473      0.624672   \n","AS1_B03_1000      0.730212      1.000000     -0.963065      0.419656   \n","AS1_B04_1000     -0.847473     -0.963065      1.000000     -0.453830   \n","AS1_B05_1000      0.624672      0.419656     -0.453830      1.000000   \n","AS1_B06_1000      0.826015      0.476841     -0.573565      0.821788   \n","AS1_B07_1000      0.665380      0.322374     -0.372089      0.641102   \n","AS1_B08_1000      0.533243      0.262545     -0.264205      0.719745   \n","AS1_B09_1000      0.487741      0.321681     -0.321898      0.667080   \n","AS1_B10_1000      0.300626      0.077483     -0.101518      0.457350   \n","AS1_B11_1000      0.216483      0.163598     -0.162416      0.122636   \n","AS1_B12_1000      0.008867     -0.110282      0.075361     -0.008006   \n","AS1_B13_1000      0.778249      0.564887     -0.631421      0.454659   \n","AS1_B14_1000      0.231916      0.052292     -0.006754      0.455568   \n","AS1_B15_1000      0.671888      0.421978     -0.513994      0.495061   \n","AS1_B16_1000      0.461164      0.246435     -0.265393      0.459379   \n","AS1_B17_1000      0.440043      0.139787     -0.153537      0.608900   \n","AS1_B18_1000      0.556319      0.626092     -0.630524      0.605746   \n","AS1_B19_1000      0.391156      0.202407     -0.201330      0.560320   \n","AS1_B20_1000      0.330130      0.115774     -0.121627      0.505352   \n","AS1_B21_1000      0.233472     -0.097781      0.088920      0.437128   \n","AS1_B23_1000      0.495018      0.417275     -0.385892      0.536202   \n","AS1_B24_1000      0.740685      0.673720     -0.730614      0.483955   \n","HYPERTENSION     -0.049610     -0.118918      0.104365     -0.033586   \n","\n","              AS1_B06_1000  AS1_B07_1000  AS1_B08_1000  AS1_B09_1000  \\\n","AS1_B02_1000      0.826015      0.665380      0.533243      0.487741   \n","AS1_B03_1000      0.476841      0.322374      0.262545      0.321681   \n","AS1_B04_1000     -0.573565     -0.372089     -0.264205     -0.321898   \n","AS1_B05_1000      0.821788      0.641102      0.719745      0.667080   \n","AS1_B06_1000      1.000000      0.757977      0.736095      0.537790   \n","AS1_B07_1000      0.757977      1.000000      0.786161      0.667472   \n","AS1_B08_1000      0.736095      0.786161      1.000000      0.716145   \n","AS1_B09_1000      0.537790      0.667472      0.716145      1.000000   \n","AS1_B10_1000      0.402381      0.445738      0.590720      0.586973   \n","AS1_B11_1000      0.184786      0.206929      0.229526      0.204687   \n","AS1_B12_1000      0.055862      0.023067      0.073467      0.035997   \n","AS1_B13_1000      0.636092      0.644570      0.616639      0.508912   \n","AS1_B14_1000      0.367453      0.583860      0.785674      0.621790   \n","AS1_B15_1000      0.598631      0.526269      0.415672      0.399250   \n","AS1_B16_1000      0.492365      0.583938      0.601529      0.533195   \n","AS1_B17_1000      0.596840      0.802257      0.806449      0.767380   \n","AS1_B18_1000      0.548793      0.267400      0.286663      0.366084   \n","AS1_B19_1000      0.440889      0.646802      0.689860      0.966639   \n","AS1_B20_1000      0.445345      0.525512      0.655829      0.628895   \n","AS1_B21_1000      0.495191      0.717707      0.769953      0.569728   \n","AS1_B23_1000      0.475567      0.653184      0.666859      0.634395   \n","AS1_B24_1000      0.566849      0.404211      0.315668      0.389412   \n","HYPERTENSION     -0.012975     -0.002160     -0.001727     -0.014014   \n","\n","              AS1_B10_1000  AS1_B11_1000  ...  AS1_B15_1000  AS1_B16_1000  \\\n","AS1_B02_1000      0.300626      0.216483  ...      0.671888      0.461164   \n","AS1_B03_1000      0.077483      0.163598  ...      0.421978      0.246435   \n","AS1_B04_1000     -0.101518     -0.162416  ...     -0.513994     -0.265393   \n","AS1_B05_1000      0.457350      0.122636  ...      0.495061      0.459379   \n","AS1_B06_1000      0.402381      0.184786  ...      0.598631      0.492365   \n","AS1_B07_1000      0.445738      0.206929  ...      0.526269      0.583938   \n","AS1_B08_1000      0.590720      0.229526  ...      0.415672      0.601529   \n","AS1_B09_1000      0.586973      0.204687  ...      0.399250      0.533195   \n","AS1_B10_1000      1.000000      0.184733  ...      0.198034      0.393814   \n","AS1_B11_1000      0.184733      1.000000  ...      0.168589      0.086386   \n","AS1_B12_1000      0.164698      0.747889  ...      0.035044     -0.089794   \n","AS1_B13_1000      0.352423      0.244551  ...      0.541907      0.515292   \n","AS1_B14_1000      0.446485      0.213565  ...      0.218503      0.505516   \n","AS1_B15_1000      0.198034      0.168589  ...      1.000000      0.365788   \n","AS1_B16_1000      0.393814      0.086386  ...      0.365788      1.000000   \n","AS1_B17_1000      0.603286      0.202772  ...      0.372433      0.594864   \n","AS1_B18_1000      0.041044      0.033388  ...      0.398152      0.198397   \n","AS1_B19_1000      0.612657      0.204870  ...      0.330509      0.516340   \n","AS1_B20_1000      0.825739      0.195432  ...      0.252221      0.434284   \n","AS1_B21_1000      0.627494      0.197198  ...      0.218609      0.479457   \n","AS1_B23_1000      0.345518      0.115679  ...      0.318767      0.494686   \n","AS1_B24_1000      0.137750      0.101255  ...      0.444493      0.302283   \n","HYPERTENSION      0.020809      0.015350  ...     -0.023288     -0.007746   \n","\n","              AS1_B17_1000  AS1_B18_1000  AS1_B19_1000  AS1_B20_1000  \\\n","AS1_B02_1000      0.440043      0.556319      0.391156      0.330130   \n","AS1_B03_1000      0.139787      0.626092      0.202407      0.115774   \n","AS1_B04_1000     -0.153537     -0.630524     -0.201330     -0.121627   \n","AS1_B05_1000      0.608900      0.605746      0.560320      0.505352   \n","AS1_B06_1000      0.596840      0.548793      0.440889      0.445345   \n","AS1_B07_1000      0.802257      0.267400      0.646802      0.525512   \n","AS1_B08_1000      0.806449      0.286663      0.689860      0.655829   \n","AS1_B09_1000      0.767380      0.366084      0.966639      0.628895   \n","AS1_B10_1000      0.603286      0.041044      0.612657      0.825739   \n","AS1_B11_1000      0.202772      0.033388      0.204870      0.195432   \n","AS1_B12_1000      0.074140     -0.113597      0.060959      0.075554   \n","AS1_B13_1000      0.483719      0.287964      0.477173      0.361886   \n","AS1_B14_1000      0.701882      0.106181      0.638509      0.553284   \n","AS1_B15_1000      0.372433      0.398152      0.330509      0.252221   \n","AS1_B16_1000      0.594864      0.198397      0.516340      0.434284   \n","AS1_B17_1000      1.000000      0.158026      0.783690      0.608279   \n","AS1_B18_1000      0.158026      1.000000      0.170145      0.085955   \n","AS1_B19_1000      0.783690      0.170145      1.000000      0.645132   \n","AS1_B20_1000      0.608279      0.085955      0.645132      1.000000   \n","AS1_B21_1000      0.800865     -0.059571      0.620416      0.651464   \n","AS1_B23_1000      0.614078      0.330639      0.598415      0.457471   \n","AS1_B24_1000      0.232814      0.776749      0.245194      0.152689   \n","HYPERTENSION      0.013709     -0.086723      0.000467      0.038610   \n","\n","              AS1_B21_1000  AS1_B23_1000  AS1_B24_1000  HYPERTENSION  \n","AS1_B02_1000      0.233472      0.495018      0.740685     -0.049610  \n","AS1_B03_1000     -0.097781      0.417275      0.673720     -0.118918  \n","AS1_B04_1000      0.088920     -0.385892     -0.730614      0.104365  \n","AS1_B05_1000      0.437128      0.536202      0.483955     -0.033586  \n","AS1_B06_1000      0.495191      0.475567      0.566849     -0.012975  \n","AS1_B07_1000      0.717707      0.653184      0.404211     -0.002160  \n","AS1_B08_1000      0.769953      0.666859      0.315668     -0.001727  \n","AS1_B09_1000      0.569728      0.634395      0.389412     -0.014014  \n","AS1_B10_1000      0.627494      0.345518      0.137750      0.020809  \n","AS1_B11_1000      0.197198      0.115679      0.101255      0.015350  \n","AS1_B12_1000      0.131817     -0.122544     -0.080124      0.031588  \n","AS1_B13_1000      0.320812      0.526831      0.527825     -0.071912  \n","AS1_B14_1000      0.709614      0.613384      0.154621      0.018322  \n","AS1_B15_1000      0.218609      0.318767      0.444493     -0.023288  \n","AS1_B16_1000      0.479457      0.494686      0.302283     -0.007746  \n","AS1_B17_1000      0.800865      0.614078      0.232814      0.013709  \n","AS1_B18_1000     -0.059571      0.330639      0.776749     -0.086723  \n","AS1_B19_1000      0.620416      0.598415      0.245194      0.000467  \n","AS1_B20_1000      0.651464      0.457471      0.152689      0.038610  \n","AS1_B21_1000      1.000000      0.430357     -0.009287      0.065305  \n","AS1_B23_1000      0.430357      1.000000      0.425871     -0.040096  \n","AS1_B24_1000     -0.009287      0.425871      1.000000     -0.078508  \n","HYPERTENSION      0.065305     -0.040096     -0.078508      1.000000  \n","\n","[23 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-112b0300-123f-4344-96ed-698233c5bc8f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AS1_B02_1000</th>\n","      <th>AS1_B03_1000</th>\n","      <th>AS1_B04_1000</th>\n","      <th>AS1_B05_1000</th>\n","      <th>AS1_B06_1000</th>\n","      <th>AS1_B07_1000</th>\n","      <th>AS1_B08_1000</th>\n","      <th>AS1_B09_1000</th>\n","      <th>AS1_B10_1000</th>\n","      <th>AS1_B11_1000</th>\n","      <th>...</th>\n","      <th>AS1_B15_1000</th>\n","      <th>AS1_B16_1000</th>\n","      <th>AS1_B17_1000</th>\n","      <th>AS1_B18_1000</th>\n","      <th>AS1_B19_1000</th>\n","      <th>AS1_B20_1000</th>\n","      <th>AS1_B21_1000</th>\n","      <th>AS1_B23_1000</th>\n","      <th>AS1_B24_1000</th>\n","      <th>HYPERTENSION</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>AS1_B02_1000</th>\n","      <td>1.000000</td>\n","      <td>0.730212</td>\n","      <td>-0.847473</td>\n","      <td>0.624672</td>\n","      <td>0.826015</td>\n","      <td>0.665380</td>\n","      <td>0.533243</td>\n","      <td>0.487741</td>\n","      <td>0.300626</td>\n","      <td>0.216483</td>\n","      <td>...</td>\n","      <td>0.671888</td>\n","      <td>0.461164</td>\n","      <td>0.440043</td>\n","      <td>0.556319</td>\n","      <td>0.391156</td>\n","      <td>0.330130</td>\n","      <td>0.233472</td>\n","      <td>0.495018</td>\n","      <td>0.740685</td>\n","      <td>-0.049610</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B03_1000</th>\n","      <td>0.730212</td>\n","      <td>1.000000</td>\n","      <td>-0.963065</td>\n","      <td>0.419656</td>\n","      <td>0.476841</td>\n","      <td>0.322374</td>\n","      <td>0.262545</td>\n","      <td>0.321681</td>\n","      <td>0.077483</td>\n","      <td>0.163598</td>\n","      <td>...</td>\n","      <td>0.421978</td>\n","      <td>0.246435</td>\n","      <td>0.139787</td>\n","      <td>0.626092</td>\n","      <td>0.202407</td>\n","      <td>0.115774</td>\n","      <td>-0.097781</td>\n","      <td>0.417275</td>\n","      <td>0.673720</td>\n","      <td>-0.118918</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B04_1000</th>\n","      <td>-0.847473</td>\n","      <td>-0.963065</td>\n","      <td>1.000000</td>\n","      <td>-0.453830</td>\n","      <td>-0.573565</td>\n","      <td>-0.372089</td>\n","      <td>-0.264205</td>\n","      <td>-0.321898</td>\n","      <td>-0.101518</td>\n","      <td>-0.162416</td>\n","      <td>...</td>\n","      <td>-0.513994</td>\n","      <td>-0.265393</td>\n","      <td>-0.153537</td>\n","      <td>-0.630524</td>\n","      <td>-0.201330</td>\n","      <td>-0.121627</td>\n","      <td>0.088920</td>\n","      <td>-0.385892</td>\n","      <td>-0.730614</td>\n","      <td>0.104365</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B05_1000</th>\n","      <td>0.624672</td>\n","      <td>0.419656</td>\n","      <td>-0.453830</td>\n","      <td>1.000000</td>\n","      <td>0.821788</td>\n","      <td>0.641102</td>\n","      <td>0.719745</td>\n","      <td>0.667080</td>\n","      <td>0.457350</td>\n","      <td>0.122636</td>\n","      <td>...</td>\n","      <td>0.495061</td>\n","      <td>0.459379</td>\n","      <td>0.608900</td>\n","      <td>0.605746</td>\n","      <td>0.560320</td>\n","      <td>0.505352</td>\n","      <td>0.437128</td>\n","      <td>0.536202</td>\n","      <td>0.483955</td>\n","      <td>-0.033586</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B06_1000</th>\n","      <td>0.826015</td>\n","      <td>0.476841</td>\n","      <td>-0.573565</td>\n","      <td>0.821788</td>\n","      <td>1.000000</td>\n","      <td>0.757977</td>\n","      <td>0.736095</td>\n","      <td>0.537790</td>\n","      <td>0.402381</td>\n","      <td>0.184786</td>\n","      <td>...</td>\n","      <td>0.598631</td>\n","      <td>0.492365</td>\n","      <td>0.596840</td>\n","      <td>0.548793</td>\n","      <td>0.440889</td>\n","      <td>0.445345</td>\n","      <td>0.495191</td>\n","      <td>0.475567</td>\n","      <td>0.566849</td>\n","      <td>-0.012975</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B07_1000</th>\n","      <td>0.665380</td>\n","      <td>0.322374</td>\n","      <td>-0.372089</td>\n","      <td>0.641102</td>\n","      <td>0.757977</td>\n","      <td>1.000000</td>\n","      <td>0.786161</td>\n","      <td>0.667472</td>\n","      <td>0.445738</td>\n","      <td>0.206929</td>\n","      <td>...</td>\n","      <td>0.526269</td>\n","      <td>0.583938</td>\n","      <td>0.802257</td>\n","      <td>0.267400</td>\n","      <td>0.646802</td>\n","      <td>0.525512</td>\n","      <td>0.717707</td>\n","      <td>0.653184</td>\n","      <td>0.404211</td>\n","      <td>-0.002160</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B08_1000</th>\n","      <td>0.533243</td>\n","      <td>0.262545</td>\n","      <td>-0.264205</td>\n","      <td>0.719745</td>\n","      <td>0.736095</td>\n","      <td>0.786161</td>\n","      <td>1.000000</td>\n","      <td>0.716145</td>\n","      <td>0.590720</td>\n","      <td>0.229526</td>\n","      <td>...</td>\n","      <td>0.415672</td>\n","      <td>0.601529</td>\n","      <td>0.806449</td>\n","      <td>0.286663</td>\n","      <td>0.689860</td>\n","      <td>0.655829</td>\n","      <td>0.769953</td>\n","      <td>0.666859</td>\n","      <td>0.315668</td>\n","      <td>-0.001727</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B09_1000</th>\n","      <td>0.487741</td>\n","      <td>0.321681</td>\n","      <td>-0.321898</td>\n","      <td>0.667080</td>\n","      <td>0.537790</td>\n","      <td>0.667472</td>\n","      <td>0.716145</td>\n","      <td>1.000000</td>\n","      <td>0.586973</td>\n","      <td>0.204687</td>\n","      <td>...</td>\n","      <td>0.399250</td>\n","      <td>0.533195</td>\n","      <td>0.767380</td>\n","      <td>0.366084</td>\n","      <td>0.966639</td>\n","      <td>0.628895</td>\n","      <td>0.569728</td>\n","      <td>0.634395</td>\n","      <td>0.389412</td>\n","      <td>-0.014014</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B10_1000</th>\n","      <td>0.300626</td>\n","      <td>0.077483</td>\n","      <td>-0.101518</td>\n","      <td>0.457350</td>\n","      <td>0.402381</td>\n","      <td>0.445738</td>\n","      <td>0.590720</td>\n","      <td>0.586973</td>\n","      <td>1.000000</td>\n","      <td>0.184733</td>\n","      <td>...</td>\n","      <td>0.198034</td>\n","      <td>0.393814</td>\n","      <td>0.603286</td>\n","      <td>0.041044</td>\n","      <td>0.612657</td>\n","      <td>0.825739</td>\n","      <td>0.627494</td>\n","      <td>0.345518</td>\n","      <td>0.137750</td>\n","      <td>0.020809</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B11_1000</th>\n","      <td>0.216483</td>\n","      <td>0.163598</td>\n","      <td>-0.162416</td>\n","      <td>0.122636</td>\n","      <td>0.184786</td>\n","      <td>0.206929</td>\n","      <td>0.229526</td>\n","      <td>0.204687</td>\n","      <td>0.184733</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.168589</td>\n","      <td>0.086386</td>\n","      <td>0.202772</td>\n","      <td>0.033388</td>\n","      <td>0.204870</td>\n","      <td>0.195432</td>\n","      <td>0.197198</td>\n","      <td>0.115679</td>\n","      <td>0.101255</td>\n","      <td>0.015350</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B12_1000</th>\n","      <td>0.008867</td>\n","      <td>-0.110282</td>\n","      <td>0.075361</td>\n","      <td>-0.008006</td>\n","      <td>0.055862</td>\n","      <td>0.023067</td>\n","      <td>0.073467</td>\n","      <td>0.035997</td>\n","      <td>0.164698</td>\n","      <td>0.747889</td>\n","      <td>...</td>\n","      <td>0.035044</td>\n","      <td>-0.089794</td>\n","      <td>0.074140</td>\n","      <td>-0.113597</td>\n","      <td>0.060959</td>\n","      <td>0.075554</td>\n","      <td>0.131817</td>\n","      <td>-0.122544</td>\n","      <td>-0.080124</td>\n","      <td>0.031588</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B13_1000</th>\n","      <td>0.778249</td>\n","      <td>0.564887</td>\n","      <td>-0.631421</td>\n","      <td>0.454659</td>\n","      <td>0.636092</td>\n","      <td>0.644570</td>\n","      <td>0.616639</td>\n","      <td>0.508912</td>\n","      <td>0.352423</td>\n","      <td>0.244551</td>\n","      <td>...</td>\n","      <td>0.541907</td>\n","      <td>0.515292</td>\n","      <td>0.483719</td>\n","      <td>0.287964</td>\n","      <td>0.477173</td>\n","      <td>0.361886</td>\n","      <td>0.320812</td>\n","      <td>0.526831</td>\n","      <td>0.527825</td>\n","      <td>-0.071912</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B14_1000</th>\n","      <td>0.231916</td>\n","      <td>0.052292</td>\n","      <td>-0.006754</td>\n","      <td>0.455568</td>\n","      <td>0.367453</td>\n","      <td>0.583860</td>\n","      <td>0.785674</td>\n","      <td>0.621790</td>\n","      <td>0.446485</td>\n","      <td>0.213565</td>\n","      <td>...</td>\n","      <td>0.218503</td>\n","      <td>0.505516</td>\n","      <td>0.701882</td>\n","      <td>0.106181</td>\n","      <td>0.638509</td>\n","      <td>0.553284</td>\n","      <td>0.709614</td>\n","      <td>0.613384</td>\n","      <td>0.154621</td>\n","      <td>0.018322</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B15_1000</th>\n","      <td>0.671888</td>\n","      <td>0.421978</td>\n","      <td>-0.513994</td>\n","      <td>0.495061</td>\n","      <td>0.598631</td>\n","      <td>0.526269</td>\n","      <td>0.415672</td>\n","      <td>0.399250</td>\n","      <td>0.198034</td>\n","      <td>0.168589</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.365788</td>\n","      <td>0.372433</td>\n","      <td>0.398152</td>\n","      <td>0.330509</td>\n","      <td>0.252221</td>\n","      <td>0.218609</td>\n","      <td>0.318767</td>\n","      <td>0.444493</td>\n","      <td>-0.023288</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B16_1000</th>\n","      <td>0.461164</td>\n","      <td>0.246435</td>\n","      <td>-0.265393</td>\n","      <td>0.459379</td>\n","      <td>0.492365</td>\n","      <td>0.583938</td>\n","      <td>0.601529</td>\n","      <td>0.533195</td>\n","      <td>0.393814</td>\n","      <td>0.086386</td>\n","      <td>...</td>\n","      <td>0.365788</td>\n","      <td>1.000000</td>\n","      <td>0.594864</td>\n","      <td>0.198397</td>\n","      <td>0.516340</td>\n","      <td>0.434284</td>\n","      <td>0.479457</td>\n","      <td>0.494686</td>\n","      <td>0.302283</td>\n","      <td>-0.007746</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B17_1000</th>\n","      <td>0.440043</td>\n","      <td>0.139787</td>\n","      <td>-0.153537</td>\n","      <td>0.608900</td>\n","      <td>0.596840</td>\n","      <td>0.802257</td>\n","      <td>0.806449</td>\n","      <td>0.767380</td>\n","      <td>0.603286</td>\n","      <td>0.202772</td>\n","      <td>...</td>\n","      <td>0.372433</td>\n","      <td>0.594864</td>\n","      <td>1.000000</td>\n","      <td>0.158026</td>\n","      <td>0.783690</td>\n","      <td>0.608279</td>\n","      <td>0.800865</td>\n","      <td>0.614078</td>\n","      <td>0.232814</td>\n","      <td>0.013709</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B18_1000</th>\n","      <td>0.556319</td>\n","      <td>0.626092</td>\n","      <td>-0.630524</td>\n","      <td>0.605746</td>\n","      <td>0.548793</td>\n","      <td>0.267400</td>\n","      <td>0.286663</td>\n","      <td>0.366084</td>\n","      <td>0.041044</td>\n","      <td>0.033388</td>\n","      <td>...</td>\n","      <td>0.398152</td>\n","      <td>0.198397</td>\n","      <td>0.158026</td>\n","      <td>1.000000</td>\n","      <td>0.170145</td>\n","      <td>0.085955</td>\n","      <td>-0.059571</td>\n","      <td>0.330639</td>\n","      <td>0.776749</td>\n","      <td>-0.086723</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B19_1000</th>\n","      <td>0.391156</td>\n","      <td>0.202407</td>\n","      <td>-0.201330</td>\n","      <td>0.560320</td>\n","      <td>0.440889</td>\n","      <td>0.646802</td>\n","      <td>0.689860</td>\n","      <td>0.966639</td>\n","      <td>0.612657</td>\n","      <td>0.204870</td>\n","      <td>...</td>\n","      <td>0.330509</td>\n","      <td>0.516340</td>\n","      <td>0.783690</td>\n","      <td>0.170145</td>\n","      <td>1.000000</td>\n","      <td>0.645132</td>\n","      <td>0.620416</td>\n","      <td>0.598415</td>\n","      <td>0.245194</td>\n","      <td>0.000467</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B20_1000</th>\n","      <td>0.330130</td>\n","      <td>0.115774</td>\n","      <td>-0.121627</td>\n","      <td>0.505352</td>\n","      <td>0.445345</td>\n","      <td>0.525512</td>\n","      <td>0.655829</td>\n","      <td>0.628895</td>\n","      <td>0.825739</td>\n","      <td>0.195432</td>\n","      <td>...</td>\n","      <td>0.252221</td>\n","      <td>0.434284</td>\n","      <td>0.608279</td>\n","      <td>0.085955</td>\n","      <td>0.645132</td>\n","      <td>1.000000</td>\n","      <td>0.651464</td>\n","      <td>0.457471</td>\n","      <td>0.152689</td>\n","      <td>0.038610</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B21_1000</th>\n","      <td>0.233472</td>\n","      <td>-0.097781</td>\n","      <td>0.088920</td>\n","      <td>0.437128</td>\n","      <td>0.495191</td>\n","      <td>0.717707</td>\n","      <td>0.769953</td>\n","      <td>0.569728</td>\n","      <td>0.627494</td>\n","      <td>0.197198</td>\n","      <td>...</td>\n","      <td>0.218609</td>\n","      <td>0.479457</td>\n","      <td>0.800865</td>\n","      <td>-0.059571</td>\n","      <td>0.620416</td>\n","      <td>0.651464</td>\n","      <td>1.000000</td>\n","      <td>0.430357</td>\n","      <td>-0.009287</td>\n","      <td>0.065305</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B23_1000</th>\n","      <td>0.495018</td>\n","      <td>0.417275</td>\n","      <td>-0.385892</td>\n","      <td>0.536202</td>\n","      <td>0.475567</td>\n","      <td>0.653184</td>\n","      <td>0.666859</td>\n","      <td>0.634395</td>\n","      <td>0.345518</td>\n","      <td>0.115679</td>\n","      <td>...</td>\n","      <td>0.318767</td>\n","      <td>0.494686</td>\n","      <td>0.614078</td>\n","      <td>0.330639</td>\n","      <td>0.598415</td>\n","      <td>0.457471</td>\n","      <td>0.430357</td>\n","      <td>1.000000</td>\n","      <td>0.425871</td>\n","      <td>-0.040096</td>\n","    </tr>\n","    <tr>\n","      <th>AS1_B24_1000</th>\n","      <td>0.740685</td>\n","      <td>0.673720</td>\n","      <td>-0.730614</td>\n","      <td>0.483955</td>\n","      <td>0.566849</td>\n","      <td>0.404211</td>\n","      <td>0.315668</td>\n","      <td>0.389412</td>\n","      <td>0.137750</td>\n","      <td>0.101255</td>\n","      <td>...</td>\n","      <td>0.444493</td>\n","      <td>0.302283</td>\n","      <td>0.232814</td>\n","      <td>0.776749</td>\n","      <td>0.245194</td>\n","      <td>0.152689</td>\n","      <td>-0.009287</td>\n","      <td>0.425871</td>\n","      <td>1.000000</td>\n","      <td>-0.078508</td>\n","    </tr>\n","    <tr>\n","      <th>HYPERTENSION</th>\n","      <td>-0.049610</td>\n","      <td>-0.118918</td>\n","      <td>0.104365</td>\n","      <td>-0.033586</td>\n","      <td>-0.012975</td>\n","      <td>-0.002160</td>\n","      <td>-0.001727</td>\n","      <td>-0.014014</td>\n","      <td>0.020809</td>\n","      <td>0.015350</td>\n","      <td>...</td>\n","      <td>-0.023288</td>\n","      <td>-0.007746</td>\n","      <td>0.013709</td>\n","      <td>-0.086723</td>\n","      <td>0.000467</td>\n","      <td>0.038610</td>\n","      <td>0.065305</td>\n","      <td>-0.040096</td>\n","      <td>-0.078508</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-112b0300-123f-4344-96ed-698233c5bc8f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-112b0300-123f-4344-96ed-698233c5bc8f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-112b0300-123f-4344-96ed-698233c5bc8f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"TFohIP6JTTjJ"},"source":["## dataset 분리\n","- train, test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652360300150,"user":{"displayName":"황승현","userId":"10828741460016505216"},"user_tz":-540},"id":"3gypz7ujii4n","outputId":"6520bcac-9ee4-4b61-9fbc-4ed8b1e57528"},"outputs":[{"output_type":"stream","name":"stdout","text":["(7763, 22) (1941, 22) (7763,) (1941,)\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=415)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"]},{"cell_type":"markdown","source":["## 모델 제작 CNN"],"metadata":{"id":"F7qUbPOQouUZ"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"n91A7AYMqTgE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ClearTrainingOutput(keras.callbacks.Callback):\n","  def on_train_end(*args, **kwargs):\n","    IPython.display.clear_output(wait = True)\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n","# 검증 데이터 손실이 3회 증가하면 정해진 에포크가 도달하지 못하였더라도 학습을 조기 종료(Early Stopping)\n","\n","mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n","# 검증 데이터의 정확도(val_acc)가 이전보다 좋아질 경우에만 모델을 저장"],"metadata":{"id":"q62K6UwMtgXD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCH = 128\n","DROPOUT = 0.05\n","LEARNINGRATE = 0.01\n","i = 8\n","\n","embedding_dim = 256 # 임베딩 벡터의 차원\n","dropout_ratio = 0.05 # 드롭아웃 비율\n","num_filters = 256 # 커널의 수\n","kernel_size = 3 # 커널의 크기\n","hidden_units = 16 # 뉴런의 수"],"metadata":{"id":"afoeKYnhtpvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 8 # 임베딩 벡터의 차원\n","dropout_ratio = 0.05 # 드롭아웃 비율\n","num_filters = 8 # 커널의 수\n","kernel_size = 3 # 커널의 크기\n","hidden_units = 64 # 뉴런의 수\n","\n","model = Sequential()\n","\n","model.add(Embedding(len(X_train), embedding_dim))\n","model.add(Dropout(dropout_ratio))\n","\n","model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n","model.add(GlobalMaxPooling1D())\n","\n","model.add(Dense(hidden_units, activation='relu'))\n","model.add(Dropout(dropout_ratio))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n","history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[es, mc])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1reHIsqo8to","executionInfo":{"status":"ok","timestamp":1652360361593,"user_tz":-540,"elapsed":33262,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"ba97258a-8ae7-41ff-e598-8ed6ecdf8188"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","243/243 [==============================] - ETA: 0s - loss: 0.1910 - acc: 0.7608\n","Epoch 1: val_acc improved from -inf to 0.77846, saving model to best_model.h5\n","243/243 [==============================] - 14s 8ms/step - loss: 0.1910 - acc: 0.7608 - val_loss: 0.1745 - val_acc: 0.7785\n","Epoch 2/100\n","242/243 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.7602\n","Epoch 2: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 7ms/step - loss: 0.1829 - acc: 0.7605 - val_loss: 0.1736 - val_acc: 0.7785\n","Epoch 3/100\n","239/243 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.7601\n","Epoch 3: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 8ms/step - loss: 0.1827 - acc: 0.7605 - val_loss: 0.1725 - val_acc: 0.7785\n","Epoch 4/100\n","243/243 [==============================] - ETA: 0s - loss: 0.1824 - acc: 0.7605\n","Epoch 4: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 7ms/step - loss: 0.1824 - acc: 0.7605 - val_loss: 0.1733 - val_acc: 0.7785\n","Epoch 5/100\n","239/243 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.7609\n","Epoch 5: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 7ms/step - loss: 0.1824 - acc: 0.7605 - val_loss: 0.1731 - val_acc: 0.7785\n","Epoch 6/100\n","243/243 [==============================] - ETA: 0s - loss: 0.1821 - acc: 0.7605\n","Epoch 6: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 7ms/step - loss: 0.1821 - acc: 0.7605 - val_loss: 0.1725 - val_acc: 0.7785\n","Epoch 7/100\n","241/243 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.7601\n","Epoch 7: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 8ms/step - loss: 0.1826 - acc: 0.7605 - val_loss: 0.1736 - val_acc: 0.7785\n","Epoch 8/100\n","236/243 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.7618\n","Epoch 8: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 7ms/step - loss: 0.1825 - acc: 0.7605 - val_loss: 0.1746 - val_acc: 0.7785\n","Epoch 9/100\n","243/243 [==============================] - ETA: 0s - loss: 0.1827 - acc: 0.7605\n","Epoch 9: val_acc did not improve from 0.77846\n","243/243 [==============================] - 2s 8ms/step - loss: 0.1827 - acc: 0.7605 - val_loss: 0.1732 - val_acc: 0.7785\n","Epoch 9: early stopping\n"]}]},{"cell_type":"code","source":["model.summary()\n","model.evaluate(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGCWYWdZ84sl","executionInfo":{"status":"ok","timestamp":1652269983020,"user_tz":-540,"elapsed":788,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"571ca252-5121-4864-9bdd-b2440835ed52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, None, 8)           62104     \n","                                                                 \n"," dropout_7 (Dropout)         (None, None, 8)           0         \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, None, 8)           200       \n","                                                                 \n"," global_max_pooling1d_3 (Glo  (None, 8)                0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                576       \n","                                                                 \n"," dropout_8 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dropout_9 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dropout_10 (Dropout)        (None, 64)                0         \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 71,265\n","Trainable params: 71,265\n","Non-trainable params: 0\n","_________________________________________________________________\n","61/61 [==============================] - 0s 3ms/step - loss: 0.1741 - acc: 0.7785\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.17405691742897034, 0.7784647345542908]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["EPOCH = 64\n","DROPOUT = 0.05\n","LEARNINGRATE = 0.01\n","embedding_dim = 256 # 임베딩 벡터의 차원\n","dropout_ratio = 0.05 # 드롭아웃 비율\n","num_filters = 256 # 커널의 수\n","kernel_size = 3 # 커널의 크기\n","hidden_units = 16 # 뉴런의 수\n","\n","def model_builder(hp):\n","  model = Sequential()\n","  hp_units = hp.Int('units', min_value = 4, max_value = EPOCH, step = 4)\n","  hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.05, step=0.05)\n","  hp_emb_dim = hp.Int('embedding_dim', min_value = 64, max_value = 512, step = 64)\n","  hp_filters = hp.Int('filters', min_value = 8, max_value = 5)\n","\n","  model.add(Embedding(len(X_train), embedding_dim))\n","  model.add(Dropout(dropout_ratio))\n","\n","  model.add(Conv1D(hp_filters, kernel_size, padding='valid', activation='relu'))\n","  model.add(GlobalMaxPooling1D())\n","  \n","  model.add(Dropout(hp_dropout))\n","  model.add(Dense(units = hp_units, activation='relu'))\n","\n","  model.add(Dropout(hp_dropout))\n","  model.add(Dense(1, activation='sigmoid')) # 출력층\n","\n","  # Tune the learning rate for the optimizer S\n","  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3]) # 0.01 or 0.001\n","\n","  model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n","                # loss=\"binary_crossentropy\", # 손실함수: binary_crossentropy\n","                loss='mse'\n","                # metrics = ['accuracy']\n","                ) # 평가지표\n","\n","  # model.compile(optimizer='rmsprop', \n","  #               loss='mse', metrics=['mse']) #손실함수: MSE(mean squared error)\n","  \n","  return model"],"metadata":{"id":"VCn_E8XRtMuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input_shape = (X_train.shape[1],)\n","# hypermodel = RegressionHyperModel(input_shape)\n","\n","tuner = kt.Hyperband(model_builder,\n","                     objective = 'val_accuracy',\n","                     max_epochs = EPOCH,\n","                     hyperband_iterations = EPOCH,\n","                     directory = '/content/drive/MyDrive/Colab Notebooks/HyperTension_Returns',\n","                     project_name = '0507_2')\n","\n","tuner.search(X_train, y_train,\n","             epochs = EPOCH,\n","             validation_split=0.2,\n","             callbacks = [ClearTrainingOutput(), es, mc])"],"metadata":{"id":"2ZFH5wtCtSQa","colab":{"base_uri":"https://localhost:8080/","height":378},"executionInfo":{"status":"error","timestamp":1652270416172,"user_tz":-540,"elapsed":8619,"user":{"displayName":"황승현","userId":"10828741460016505216"}},"outputId":"bb5b366d-4194-43df-8c50-873ffc250ecd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-cedb000328fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m              \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m              \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m              callbacks = [ClearTrainingOutput(), es, mc])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         return tuner_utils.convert_to_metrics_dict(\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner_utils.py\u001b[0m in \u001b[0;36mconvert_to_metrics_dict\u001b[0;34m(results, objective, func_name)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbest_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;31m# Support multi-objective.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/objective.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mobjective\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbetter_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"]}]},{"cell_type":"code","source":["# Get the optimal hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n","\n","print(f\"\"\"\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","{best_hps.get('units')}\n","최적의 학습률은\n","{best_hps.get('learning_rate')}\n","최적의 드롭아웃 확률은\n","{best_hps.get('dropout')}.\n","\"\"\")"],"metadata":{"id":"evcwPreBtXWz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDUXEutK0KpZ"},"source":["## 기존 모델 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OV0_n89I0TrB"},"outputs":[],"source":["EPOCH = 128\n","DROPOUT = 0.05\n","LEARNINGRATE = 0.01\n","i = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5M6VMh80KKI"},"outputs":[],"source":["model = Sequential()\n","model.add(Dense(i, activation='relu'))  # input layer requires input_dim param\n","\n","model.add(Dropout(DROPOUT))\n","model.add(Dense(i, activation='relu'))\n","\n","model.add(Dropout(DROPOUT))\n","model.add(Dense(i, activation='relu'))\n","\n","model.add(Dense(1, activation='sigmoid'))  # sigmoid instead of relu for final probability between 0 and 1\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer = Adam(learning_rate = LEARNINGRATE),\n","              metrics=['accuracy'])\n","\n","history = model.fit(X_train, y_train, epochs=EPOCH, verbose=0)\n","scores = model.evaluate(X_test, y_test)\n","\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4E3CMRY1ncC"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OjYoMf31tUR"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"C6OmXm6cTcC7"},"source":["## 모델 제작 Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2sHaKSbe0Ak"},"outputs":[],"source":["import IPython\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","!pip install -q -U keras-tuner\n","import keras_tuner as kt\n","from keras_tuner import HyperModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qqVtCfMaNGzL"},"outputs":[],"source":["EPOCH = 64\n","DROPOUT = 0.05\n","LEARNINGRATE = 0.01\n","i = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVLlrCtCTGnd"},"outputs":[],"source":["def model_builder(hp):\n","  model = Sequential()\n","  hp_units = hp.Int('units', min_value = 4, max_value = EPOCH, step = 4)\n","  # hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.05, step=0.05)\n","  # Tune the learning rate for the optimizer S\n","  # hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3]) # 0.01 or 0.001\n","\n","\n","  model.add(Dense(units = hp_units, activation='relu')) # input_shape = 63\n","  \n","  model.add(Dropout(0.1))\n","  model.add(Dense(units = hp_units, activation='relu'))\n","  \n","  model.add(Dropout(0.1))\n","  model.add(Dense(units = hp_units, activation='relu'))\n","  \n","  model.add(Dropout(0.1))\n","  model.add(Dense(units = hp_units, activation='relu'))\n","  \n","  model.add(Dropout(0.1))\n","  model.add(Dense(units = hp_units, activation='relu'))\n","\n","  model.add(Dropout(0.1))\n","  model.add(Dense(1, activation='sigmoid')) # 출력층\n","\n","  model.compile(optimizer = Adam(learning_rate = 0.001),\n","                loss=\"binary_crossentropy\", # 손실함수: binary_crossentropy\n","                metrics = ['accuracy']) # 평가지표\n","\n","  # model.compile(optimizer='rmsprop', \n","  #               loss='mse', metrics=['mse']) #손실함수: MSE(mean squared error)\n","  \n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4kBZRtZeZIm"},"outputs":[],"source":["class ClearTrainingOutput(keras.callbacks.Callback):\n","  def on_train_end(*args, **kwargs):\n","    IPython.display.clear_output(wait = True)\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n","# 검증 데이터 손실이 3회 증가하면 정해진 에포크가 도달하지 못하였더라도 학습을 조기 종료(Early Stopping)\n","\n","mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n","# 검증 데이터의 정확도(val_acc)가 이전보다 좋아질 경우에만 모델을 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V60MZMY-4dZZ"},"outputs":[],"source":["# input_shape = (X_train.shape[1],)\n","# hypermodel = RegressionHyperModel(input_shape)\n","\n","tuner = kt.Hyperband(model_builder,\n","                     objective = 'val_accuracy',\n","                     max_epochs = EPOCH,\n","                     hyperband_iterations = EPOCH,\n","                     directory = '/content/drive/MyDrive/Colab Notebooks/HyperTension_Returns',\n","                     project_name = '0507_3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_G1XUdwqQ0AR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7262bb24-a5b4-451f-fd1a-8ff9b6f80057"},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 231 Complete [00h 00m 10s]\n","val_accuracy: 0.7675467133522034\n","\n","Best val_accuracy So Far: 0.7675467133522034\n","Total elapsed time: 00h 36m 42s\n","\n","Search: Running Trial #232\n","\n","Value             |Best Value So Far |Hyperparameter\n","12                |40                |units\n","0.1               |0.45              |dropout\n","0.01              |0.01              |learning_rate\n","64                |3                 |tuner/epochs\n","22                |0                 |tuner/initial_epoch\n","3                 |3                 |tuner/bracket\n","3                 |0                 |tuner/round\n","0227              |None              |tuner/trial_id\n","\n","Epoch 23/64\n","195/195 [==============================] - 2s 7ms/step - loss: 0.5651 - accuracy: 0.7531 - val_loss: 0.5439 - val_accuracy: 0.7675\n","Epoch 24/64\n","195/195 [==============================] - 1s 6ms/step - loss: 0.5541 - accuracy: 0.7588 - val_loss: 0.5408 - val_accuracy: 0.7675\n","Epoch 25/64\n","195/195 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.7588 - val_loss: 0.5407 - val_accuracy: 0.7675\n","Epoch 26/64\n","173/195 [=========================>....] - ETA: 0s - loss: 0.5500 - accuracy: 0.7608"]}],"source":["tuner.search(X_train, y_train,\n","             epochs = EPOCH,\n","             validation_split=0.2,\n","             callbacks = [ClearTrainingOutput(), es])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxPSdBDjOxGj"},"outputs":[],"source":["# Get the optimal hyperparameters\n","best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n","\n","print(f\"\"\"\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","{best_hps.get('units')}\n","최적의 학습률은\n","{best_hps.get('learning_rate')}\n","최적의 드롭아웃 확률은\n","{best_hps.get('dropout')}.\n","\"\"\")"]},{"cell_type":"markdown","metadata":{"id":"UVJB1iupYteV"},"source":["#### best_hps\n","\n","- 2021-08-08\n","  ```\n","  INFO:tensorflow:Oracle triggered exit\n","  The hyperparameter search is complete. The optimal number of units in the densely-connected layer is\n","  72, 8, 104, 32)\n","   the optimal learning rate for the optimizer is\n","  0.001\n","  drop-out is\n","  (0.03, 0.06).\n","  ```\n","  - min_value = 8, max_value = 128, step = 8\n","\n","- 2021-08-12\n","  ```\n","  Best val_accuracy So Far: 0.7678571343421936\n","  Total elapsed time: 00h 00m 33s\n","  INFO:tensorflow:Oracle triggered exit\n","  The hyperparameter search is complete. The optimal number of units in the densely-connected layer is\n","  (10, 16, 6, 24)\n","  and the optimal learning rate for the optimizer is\n","  0.0001\n","  drop-out is\n","  (0.044, 0.096).\n","  ```\n","\n","  - min_value = 2, max_value = 32, step = 2\n","\n","- 2021-08-14\n","  ```\n","  Best val_accuracy So Far: 0.7726648449897766\n","  Total elapsed time: 00h 01m 27s\n","  INFO:tensorflow:Oracle triggered exit\n","\n","  The hyperparameter search is complete. The optimal number of units in the densely-connected layer is\n","  (16, 8, 14, 8)\n","  and the optimal learning rate for the optimizer is\n","  0.0001\n","  drop-out is\n","  (0.085, 0.09).\n","  ```\n","\n","  - min_value = 4, max_value = 32, step = 2\n","\n","- 2021-08-23\n","  ```\n","  Trial 16 Complete [00h 00m 21s]\n","  val_accuracy: 0.7726648449897766\n","\n","  Best val_accuracy So Far: 0.7743818759918213\n","  Total elapsed time: 00h 01m 49s\n","  INFO:tensorflow:Oracle triggered exit\n","\n","  The hyperparameter search is complete. The optimal number of units in the densely-connected layer is\n","  28\n","  and the optimal learning rate for the optimizer is\n","  0.01\n","  drop-out is\n","  0.05.\n","  ```\n","- 중요한 변수만 했을때\n","  - 0.7743818759918213\n","  - 큰 차이 없음\n","\n","- 2021-08-29\n","  ```\n","  Trial 184 Complete [00h 00m 02s]\n","  val_accuracy: 0.7779740691184998\n","\n","  Best val_accuracy So Far: 0.7891637086868286\n","  Total elapsed time: 00h 22m 51s\n","  INFO:tensorflow:Oracle triggered exit\n","\n","  The hyperparameter search is complete.\n","  The optimal number of units in the densely-connected layer is\n","  30\n","  and the optimal learning rate for the optimizer is\n","  0.001\n","  drop-out is\n","  0.05.\n","  ```\n","\n","- 2021-08-30\n","  ```\n","  Trial 382 Complete [00h 00m 07s]\n","  val_accuracy: 0.7623953819274902\n","\n","  Best val_accuracy So Far: 0.7707662582397461\n","  Total elapsed time: 00h 27m 33s\n","  INFO:tensorflow:Oracle triggered exit\n","\n","  The hyperparameter search is complete.\n","  The optimal number of units in the densely-connected layer is\n","  22\n","  and the optimal learning rate for the optimizer is\n","  0.001\n","  drop-out is\n","  0.0.\n","  ```\n","\n","```\n","Trial 441 Complete [00h 00m 05s]\n","val_accuracy: 0.765614926815033\n","\n","Best val_accuracy So Far: 0.7701223492622375\n","Total elapsed time: 00h 33m 03s\n","INFO:tensorflow:Oracle triggered exit\n","\n","The hyperparameter search is complete.\n","The optimal number of units in the densely-connected layer is\n","30\n","and the optimal learning rate for the optimizer is\n","0.001\n","drop-out is\n","0.05.\n","```\n","\n","```\n","Trial 90 Complete [00h 00m 21s]\n","val_accuracy: 0.7604635953903198\n","\n","Best val_accuracy So Far: 0.7617514729499817\n","Total elapsed time: 00h 07m 40s\n","INFO:tensorflow:Oracle triggered exit\n","\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","56\n","최적의 학습률은\n","0.01\n","최적의 드롭아웃 확률은\n","0.2\n","```\n","\n","```\n","Trial 843 Complete [00h 00m 01s]\n","val_accuracy: 0.769478440284729\n","\n","Best val_accuracy So Far: 0.7746297717094421\n","Total elapsed time: 01h 38m 26s\n","INFO:tensorflow:Oracle triggered exit\n","\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","20\n","최적의 학습률은\n","0.001\n","최적의 드롭아웃 확률은\n","0.1.\n","```\n","```\n","jobb 제외, bmi 추가\n","\n","Trial 814 Complete [00h 00m 02s]\n","val_accuracy: 0.7675467133522034\n","\n","Best val_accuracy So Far: 0.7797810435295105\n","Total elapsed time: 01h 46m 50s\n","INFO:tensorflow:Oracle triggered exit\n","\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","92\n","최적의 학습률은\n","0.001\n","최적의 드롭아웃 확률은\n","0.25.\n","```\n","```\n","Trial 830 Complete [00h 00m 02s]\n","val_accuracy: 0.7675467133522034\n","\n","Best val_accuracy So Far: 0.7765614986419678\n","Total elapsed time: 01h 58m 33s\n","INFO:tensorflow:Oracle triggered exit\n","//하이퍼 파라미터 검색 완료//\n","최적의 은닉층 unit 수는\n","48\n","최적의 학습률은\n","0.001\n","최적의 드롭아웃 확률은\n","0.1.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKBA5Hfxmffv"},"outputs":[],"source":["model = tuner.hypermodel.build(best_hps)\n","scores = model.evaluate(X_test, y_test)\n","print(\"%s: %.2f, %s: %.2f%%\" % (model.metrics_names[0], scores[0], model.metrics_names[1], scores[1] * 100))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"HyperTension_2022-05-13","provenance":[{"file_id":"1-SwqUf9AhPaytZBuaEqc6eltQlvxB5PA","timestamp":1652441979894},{"file_id":"1a2wbt-_WiUMhPFz0gVJhT-lwdDt_fR4l","timestamp":1651894614462},{"file_id":"159lwJCTJ5YsT0NFY3hS5Y6-lGFyeUUsg","timestamp":1632649915783},{"file_id":"1N-2nv1RSG_XtFXz1ZPD6BlB7Quj508WG","timestamp":1631529678691},{"file_id":"1gLv76CEG-r8b-4vxtVwgg_vpgg9kTSug","timestamp":1631166086161},{"file_id":"1ujlUn6XfLSNJqzf9i2CG5QgMyGtQynF2","timestamp":1630565541203},{"file_id":"12P2loX6H_7ms5xju6UfDMGAzU6C5N3OL","timestamp":1630205312531},{"file_id":"1obnRRl2jn-2gZCRHeNTeckMR4bRTrVCs","timestamp":1628408629557},{"file_id":"1QeVdwLq3Mxupjc_y6Vdh2dtwbx29NzHj","timestamp":1627293784247}],"toc_visible":true,"mount_file_id":"1obnRRl2jn-2gZCRHeNTeckMR4bRTrVCs","authorship_tag":"ABX9TyO/bAn6sSLytXNv+SjHxEls"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}